{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d697b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pd.options.plotting.backend=\"plotly\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184df585",
   "metadata": {},
   "source": [
    "## Split data into Train n Test \n",
    "### split_data give X_train, y_train,  X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7b69ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, split_frac=0.3, return_val=False, rand_state=7):\n",
    "    X  = df.drop('30DayFwd', axis=1)\n",
    "    X  = df.drop('Date', axis=1)\n",
    "    y  = df['30DayFwd']\n",
    "    #print(y)\n",
    "    '''stratify = y'''\n",
    "    return train_test_split(X, y, test_size = split_frac, random_state = rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa9cfb",
   "metadata": {},
   "source": [
    "## get_model_score returns:\n",
    "### X_train, y_train score if val_score && test_score == False\n",
    "### X_train, y_train , X_val & y_val score  if Val_score == True & test_score == False\n",
    "### X_train, y_train , X_val & y_val , X_test, y_test score if Val_score == True & test_score == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "18df5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''stratify = y_train,'''\n",
    "def get_model_scores(mod, X_train, y_train, X_test, y_test, val_score = True, test_score=False):\n",
    "    \n",
    "    '''\n",
    "    #if X_train.isna() or X_test.isna() or y_train.isna() or y_test.isna():\n",
    "        #X_train.filln(0)\n",
    "        #X_test.fillna(0)\n",
    "        #y_train.fillna(0)\n",
    "        #y_test.fillna(0)\n",
    "    #X_train = X_train.drop('Date', axis=1)\n",
    "    #X_test = X_test.drop('Date', axis=1)\n",
    "    '''\n",
    "    if val_score:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                          test_size = 0.7, \n",
    "                                                          train_size = 0.3,                                                          \n",
    "                                                          random_state= 9)        \n",
    "    mod.fit(X_train, y_train)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['train_score'] = mod.score(X_train, y_train)\n",
    "    if val_score:\n",
    "        results['val_score'] = mod.score(X_val, y_val)\n",
    "        \n",
    "    if test_score:\n",
    "        results['test_score'] = mod.score(X_test, y_test)\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a26ac7",
   "metadata": {},
   "source": [
    "# Get data locally as csv file\n",
    "## With addition of 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "203ce2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_dataset():\n",
    "    data_set = pd.read_csv(r\"C:\\Users\\samina\\Desktop\\GA_DATA_SCIENCE\\Data_Sci\\Homework\\Unit4\\Final_project\\google.csv\", parse_dates=['Date'])\n",
    "    \n",
    "    #If the folowing lines in this func-> ValueError: continuous is not supported\n",
    "    #if the following lines add after func->ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
    "    \n",
    "    #data_set = data_set.fillna(0)\n",
    "    #data_set['year'] = data_set['Date'].dt.year\n",
    "    #data_set['month'] = data_set['Date'].dt.month\n",
    "    #data_set['day'] = data_set['Date'].dt.day\n",
    "    #data_set['30DayFwd']     = (data_set['Close'].shift(-30) - data_set['Close']) / data_set['Close']\n",
    "\n",
    "    #VOLUME CHANGE \n",
    "    #data_set['VolPctChange'] = data_set[['Volume']].pct_change()\n",
    "    #data_set['5DayVol']      = data_set['Volume'].pct_change().rolling(5).mean().values\n",
    "    #data_set['30DayVol']     =  data_set['Volume'].pct_change().rolling(30).mean().values\n",
    "    #data_set['252DayVol']    =  data_set['Volume'].pct_change().rolling(252).mean().values\n",
    "\n",
    "    #CLOSING STOCK RATIO\n",
    "    #data_set['Close30DRatio']  = data_set['Close'] / data_set['Close'].rolling(30).mean().values\n",
    "    #data_set['Close60DRatio']  = data_set['Close'] / data_set['Close'].rolling(60).mean().values\n",
    "    #data_set['Close252DRatio'] = data_set['Close'] / data_set['Close'].rolling(252).mean().values\n",
    "\n",
    "    #CLOSE VALUE CHANGE\n",
    "    #data_set['CloseChange']      = data_set['Close'].pct_change()\n",
    "    #data_set['Close5DayChange']  = data_set['Close'].pct_change().rolling(5).mean().values\n",
    "    #data_set['Close10DayChange'] = data_set['Close'].pct_change().rolling(10).mean().values\n",
    "    #data_set['Close60DayChange'] = data_set['Close'].pct_change().rolling(60).mean().values\n",
    "\n",
    "    #data_set = data_set.fillna(0)\n",
    "    \n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7394c53",
   "metadata": {},
   "source": [
    "# Data frame ready to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "60be18c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = local_dataset()\n",
    "\n",
    "df['30DayFwd']     = (df['Close'].shift(-30) - df['Close']) / df['Close']\n",
    "\n",
    "#VOLUME CHANGE \n",
    "df['VolPctChange'] = df[['Volume']].pct_change()\n",
    "df['5DayVol']      = df['Volume'].pct_change().rolling(5).mean().values\n",
    "df['30DayVol']     =  df['Volume'].pct_change().rolling(30).mean().values\n",
    "df['252DayVol']    =  df['Volume'].pct_change().rolling(252).mean().values\n",
    "\n",
    "#CLOSING STOCK RATIO\n",
    "df['Close30DRatio']  = df['Close'] / df['Close'].rolling(30).mean().values\n",
    "df['Close60DRatio']  = df['Close'] / df['Close'].rolling(60).mean().values\n",
    "df['Close252DRatio'] = df['Close'] / df['Close'].rolling(252).mean().values\n",
    "\n",
    "#CLOSE VALUE CHANGE\n",
    "df['CloseChange']      = df['Close'].pct_change()\n",
    "df['Close5DayChange']  = df['Close'].pct_change().rolling(5).mean().values\n",
    "df['Close10DayChange'] = df['Close'].pct_change().rolling(10).mean().values\n",
    "df['Close60DayChange'] = df['Close'].pct_change().rolling(60).mean().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "403220c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>5DayVol</th>\n",
       "      <th>30DayVol</th>\n",
       "      <th>252DayVol</th>\n",
       "      <th>Close30DRatio</th>\n",
       "      <th>Close60DRatio</th>\n",
       "      <th>Close252DRatio</th>\n",
       "      <th>CloseChange</th>\n",
       "      <th>Close5DayChange</th>\n",
       "      <th>Close10DayChange</th>\n",
       "      <th>Close60DayChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>2882.919922</td>\n",
       "      <td>2907.540039</td>\n",
       "      <td>2870.100098</td>\n",
       "      <td>2895.500000</td>\n",
       "      <td>2895.500000</td>\n",
       "      <td>955200</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023365</td>\n",
       "      <td>0.044194</td>\n",
       "      <td>0.058289</td>\n",
       "      <td>1.037946</td>\n",
       "      <td>1.079461</td>\n",
       "      <td>1.372507</td>\n",
       "      <td>0.003855</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292</th>\n",
       "      <td>2021-09-07</td>\n",
       "      <td>2894.989990</td>\n",
       "      <td>2916.479980</td>\n",
       "      <td>2890.820068</td>\n",
       "      <td>2910.379883</td>\n",
       "      <td>2910.379883</td>\n",
       "      <td>758500</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044438</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.058109</td>\n",
       "      <td>1.041817</td>\n",
       "      <td>1.082342</td>\n",
       "      <td>1.376145</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.003116</td>\n",
       "      <td>0.002483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>2021-09-08</td>\n",
       "      <td>2907.870117</td>\n",
       "      <td>2911.020020</td>\n",
       "      <td>2884.000000</td>\n",
       "      <td>2897.669922</td>\n",
       "      <td>2897.669922</td>\n",
       "      <td>774300</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067735</td>\n",
       "      <td>0.014591</td>\n",
       "      <td>0.058188</td>\n",
       "      <td>1.035269</td>\n",
       "      <td>1.075146</td>\n",
       "      <td>1.366634</td>\n",
       "      <td>-0.004367</td>\n",
       "      <td>-0.000778</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>2021-09-09</td>\n",
       "      <td>2897.669922</td>\n",
       "      <td>2913.389893</td>\n",
       "      <td>2888.679932</td>\n",
       "      <td>2898.270020</td>\n",
       "      <td>2898.270020</td>\n",
       "      <td>739900</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.059283</td>\n",
       "      <td>1.033384</td>\n",
       "      <td>1.072863</td>\n",
       "      <td>1.363495</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>-0.001259</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>2908.870117</td>\n",
       "      <td>2920.379883</td>\n",
       "      <td>2834.830078</td>\n",
       "      <td>2838.419922</td>\n",
       "      <td>2838.419922</td>\n",
       "      <td>1643500</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173258</td>\n",
       "      <td>0.065497</td>\n",
       "      <td>0.064478</td>\n",
       "      <td>1.010751</td>\n",
       "      <td>1.048609</td>\n",
       "      <td>1.332089</td>\n",
       "      <td>-0.020650</td>\n",
       "      <td>-0.003163</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>0.002069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>2864.020020</td>\n",
       "      <td>2883.820068</td>\n",
       "      <td>2845.649902</td>\n",
       "      <td>2869.300049</td>\n",
       "      <td>2869.300049</td>\n",
       "      <td>1008800</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121107</td>\n",
       "      <td>0.044590</td>\n",
       "      <td>0.062998</td>\n",
       "      <td>1.019752</td>\n",
       "      <td>1.057790</td>\n",
       "      <td>1.343208</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>-0.001758</td>\n",
       "      <td>-0.000715</td>\n",
       "      <td>0.002161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>2883.219971</td>\n",
       "      <td>2894.550049</td>\n",
       "      <td>2858.110107</td>\n",
       "      <td>2868.120117</td>\n",
       "      <td>2868.120117</td>\n",
       "      <td>945800</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149802</td>\n",
       "      <td>0.047790</td>\n",
       "      <td>0.062503</td>\n",
       "      <td>1.017544</td>\n",
       "      <td>1.055042</td>\n",
       "      <td>1.339300</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.002868</td>\n",
       "      <td>-0.001392</td>\n",
       "      <td>0.002260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298</th>\n",
       "      <td>2021-09-15</td>\n",
       "      <td>2875.179932</td>\n",
       "      <td>2911.629883</td>\n",
       "      <td>2845.120117</td>\n",
       "      <td>2904.120117</td>\n",
       "      <td>2904.120117</td>\n",
       "      <td>1032400</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163949</td>\n",
       "      <td>0.052623</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>1.028146</td>\n",
       "      <td>1.065835</td>\n",
       "      <td>1.352695</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>0.002352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>2021-09-16</td>\n",
       "      <td>2902.419922</td>\n",
       "      <td>2904.000000</td>\n",
       "      <td>2868.326904</td>\n",
       "      <td>2887.469971</td>\n",
       "      <td>2887.469971</td>\n",
       "      <td>1014600</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169386</td>\n",
       "      <td>0.056482</td>\n",
       "      <td>0.063711</td>\n",
       "      <td>1.020242</td>\n",
       "      <td>1.057476</td>\n",
       "      <td>1.341551</td>\n",
       "      <td>-0.005733</td>\n",
       "      <td>-0.000673</td>\n",
       "      <td>-0.000966</td>\n",
       "      <td>0.002184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>2875.969971</td>\n",
       "      <td>2884.989990</td>\n",
       "      <td>2821.229980</td>\n",
       "      <td>2829.270020</td>\n",
       "      <td>2829.270020</td>\n",
       "      <td>3002000</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316897</td>\n",
       "      <td>0.131178</td>\n",
       "      <td>0.069765</td>\n",
       "      <td>0.998614</td>\n",
       "      <td>1.034268</td>\n",
       "      <td>1.311286</td>\n",
       "      <td>-0.020156</td>\n",
       "      <td>-0.000574</td>\n",
       "      <td>-0.001869</td>\n",
       "      <td>0.001919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>2780.003906</td>\n",
       "      <td>2787.250000</td>\n",
       "      <td>2741.060059</td>\n",
       "      <td>2780.340088</td>\n",
       "      <td>2780.340088</td>\n",
       "      <td>1745900</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310450</td>\n",
       "      <td>0.112472</td>\n",
       "      <td>0.065521</td>\n",
       "      <td>0.980886</td>\n",
       "      <td>1.014929</td>\n",
       "      <td>1.285487</td>\n",
       "      <td>-0.017294</td>\n",
       "      <td>-0.006209</td>\n",
       "      <td>-0.003983</td>\n",
       "      <td>0.001523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302</th>\n",
       "      <td>2021-09-21</td>\n",
       "      <td>2802.340088</td>\n",
       "      <td>2816.231934</td>\n",
       "      <td>2778.110107</td>\n",
       "      <td>2792.929932</td>\n",
       "      <td>2792.929932</td>\n",
       "      <td>906500</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226784</td>\n",
       "      <td>0.099361</td>\n",
       "      <td>0.063888</td>\n",
       "      <td>0.984947</td>\n",
       "      <td>1.017958</td>\n",
       "      <td>1.288089</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>-0.005221</td>\n",
       "      <td>-0.004045</td>\n",
       "      <td>0.001636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>2021-09-22</td>\n",
       "      <td>2801.010010</td>\n",
       "      <td>2831.669922</td>\n",
       "      <td>2789.435059</td>\n",
       "      <td>2818.770020</td>\n",
       "      <td>2818.770020</td>\n",
       "      <td>1103400</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251913</td>\n",
       "      <td>0.096742</td>\n",
       "      <td>0.066543</td>\n",
       "      <td>0.993396</td>\n",
       "      <td>1.025617</td>\n",
       "      <td>1.296795</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>-0.005881</td>\n",
       "      <td>-0.002683</td>\n",
       "      <td>0.001813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>2021-09-23</td>\n",
       "      <td>2832.189941</td>\n",
       "      <td>2845.049072</td>\n",
       "      <td>2821.929932</td>\n",
       "      <td>2836.530029</td>\n",
       "      <td>2836.530029</td>\n",
       "      <td>863600</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211896</td>\n",
       "      <td>0.091223</td>\n",
       "      <td>0.065495</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>1.030104</td>\n",
       "      <td>1.301588</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>-0.003474</td>\n",
       "      <td>-0.002073</td>\n",
       "      <td>0.002023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4305</th>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>2818.919922</td>\n",
       "      <td>2858.070068</td>\n",
       "      <td>2817.010010</td>\n",
       "      <td>2852.659912</td>\n",
       "      <td>2852.659912</td>\n",
       "      <td>747500</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206752</td>\n",
       "      <td>0.087965</td>\n",
       "      <td>0.065457</td>\n",
       "      <td>1.003364</td>\n",
       "      <td>1.033795</td>\n",
       "      <td>1.305603</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.002211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>2831.709961</td>\n",
       "      <td>2850.000000</td>\n",
       "      <td>2810.000000</td>\n",
       "      <td>2830.020020</td>\n",
       "      <td>2830.020020</td>\n",
       "      <td>942200</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070974</td>\n",
       "      <td>0.101368</td>\n",
       "      <td>0.066839</td>\n",
       "      <td>0.994679</td>\n",
       "      <td>1.023719</td>\n",
       "      <td>1.291991</td>\n",
       "      <td>-0.007936</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>-0.001321</td>\n",
       "      <td>0.001939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>2781.770020</td>\n",
       "      <td>2792.129883</td>\n",
       "      <td>2714.000000</td>\n",
       "      <td>2723.679932</td>\n",
       "      <td>2723.679932</td>\n",
       "      <td>2109500</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272964</td>\n",
       "      <td>0.128167</td>\n",
       "      <td>0.069701</td>\n",
       "      <td>0.957916</td>\n",
       "      <td>0.984366</td>\n",
       "      <td>1.240614</td>\n",
       "      <td>-0.037576</td>\n",
       "      <td>-0.004855</td>\n",
       "      <td>-0.005038</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>2742.194092</td>\n",
       "      <td>2747.969971</td>\n",
       "      <td>2685.000000</td>\n",
       "      <td>2690.419922</td>\n",
       "      <td>2690.419922</td>\n",
       "      <td>1316900</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154377</td>\n",
       "      <td>0.109671</td>\n",
       "      <td>0.070245</td>\n",
       "      <td>0.946836</td>\n",
       "      <td>0.971789</td>\n",
       "      <td>1.222765</td>\n",
       "      <td>-0.012211</td>\n",
       "      <td>-0.009147</td>\n",
       "      <td>-0.007514</td>\n",
       "      <td>0.000663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>2686.500000</td>\n",
       "      <td>2711.800049</td>\n",
       "      <td>2660.000000</td>\n",
       "      <td>2665.310059</td>\n",
       "      <td>2665.310059</td>\n",
       "      <td>1764700</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265850</td>\n",
       "      <td>0.130937</td>\n",
       "      <td>0.068660</td>\n",
       "      <td>0.938727</td>\n",
       "      <td>0.962350</td>\n",
       "      <td>1.208747</td>\n",
       "      <td>-0.009333</td>\n",
       "      <td>-0.012274</td>\n",
       "      <td>-0.007874</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>2671.090088</td>\n",
       "      <td>2741.419922</td>\n",
       "      <td>2667.550049</td>\n",
       "      <td>2729.250000</td>\n",
       "      <td>2729.250000</td>\n",
       "      <td>1418600</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253513</td>\n",
       "      <td>0.116896</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.961348</td>\n",
       "      <td>0.984573</td>\n",
       "      <td>1.234990</td>\n",
       "      <td>0.023990</td>\n",
       "      <td>-0.008613</td>\n",
       "      <td>-0.003459</td>\n",
       "      <td>0.000983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date         Open         High          Low        Close  \\\n",
       "4291 2021-09-03  2882.919922  2907.540039  2870.100098  2895.500000   \n",
       "4292 2021-09-07  2894.989990  2916.479980  2890.820068  2910.379883   \n",
       "4293 2021-09-08  2907.870117  2911.020020  2884.000000  2897.669922   \n",
       "4294 2021-09-09  2897.669922  2913.389893  2888.679932  2898.270020   \n",
       "4295 2021-09-10  2908.870117  2920.379883  2834.830078  2838.419922   \n",
       "4296 2021-09-13  2864.020020  2883.820068  2845.649902  2869.300049   \n",
       "4297 2021-09-14  2883.219971  2894.550049  2858.110107  2868.120117   \n",
       "4298 2021-09-15  2875.179932  2911.629883  2845.120117  2904.120117   \n",
       "4299 2021-09-16  2902.419922  2904.000000  2868.326904  2887.469971   \n",
       "4300 2021-09-17  2875.969971  2884.989990  2821.229980  2829.270020   \n",
       "4301 2021-09-20  2780.003906  2787.250000  2741.060059  2780.340088   \n",
       "4302 2021-09-21  2802.340088  2816.231934  2778.110107  2792.929932   \n",
       "4303 2021-09-22  2801.010010  2831.669922  2789.435059  2818.770020   \n",
       "4304 2021-09-23  2832.189941  2845.049072  2821.929932  2836.530029   \n",
       "4305 2021-09-24  2818.919922  2858.070068  2817.010010  2852.659912   \n",
       "4306 2021-09-27  2831.709961  2850.000000  2810.000000  2830.020020   \n",
       "4307 2021-09-28  2781.770020  2792.129883  2714.000000  2723.679932   \n",
       "4308 2021-09-29  2742.194092  2747.969971  2685.000000  2690.419922   \n",
       "4309 2021-09-30  2686.500000  2711.800049  2660.000000  2665.310059   \n",
       "4310 2021-10-01  2671.090088  2741.419922  2667.550049  2729.250000   \n",
       "\n",
       "        Adj Close   Volume  year  month  day  ...   5DayVol  30DayVol  \\\n",
       "4291  2895.500000   955200  2021      9    3  ...  0.023365  0.044194   \n",
       "4292  2910.379883   758500  2021      9    7  ...  0.044438  0.041533   \n",
       "4293  2897.669922   774300  2021      9    8  ... -0.067735  0.014591   \n",
       "4294  2898.270020   739900  2021      9    9  ...  0.005096  0.003209   \n",
       "4295  2838.419922  1643500  2021      9   10  ...  0.173258  0.065497   \n",
       "4296  2869.300049  1008800  2021      9   13  ...  0.121107  0.044590   \n",
       "4297  2868.120117   945800  2021      9   14  ...  0.149802  0.047790   \n",
       "4298  2904.120117  1032400  2021      9   15  ...  0.163949  0.052623   \n",
       "4299  2887.469971  1014600  2021      9   16  ...  0.169386  0.056482   \n",
       "4300  2829.270020  3002000  2021      9   17  ...  0.316897  0.131178   \n",
       "4301  2780.340088  1745900  2021      9   20  ...  0.310450  0.112472   \n",
       "4302  2792.929932   906500  2021      9   21  ...  0.226784  0.099361   \n",
       "4303  2818.770020  1103400  2021      9   22  ...  0.251913  0.096742   \n",
       "4304  2836.530029   863600  2021      9   23  ...  0.211896  0.091223   \n",
       "4305  2852.659912   747500  2021      9   24  ... -0.206752  0.087965   \n",
       "4306  2830.020020   942200  2021      9   27  ... -0.070974  0.101368   \n",
       "4307  2723.679932  2109500  2021      9   28  ...  0.272964  0.128167   \n",
       "4308  2690.419922  1316900  2021      9   29  ...  0.154377  0.109671   \n",
       "4309  2665.310059  1764700  2021      9   30  ...  0.265850  0.130937   \n",
       "4310  2729.250000  1418600  2021     10    1  ...  0.253513  0.116896   \n",
       "\n",
       "      252DayVol  Close30DRatio  Close60DRatio  Close252DRatio  CloseChange  \\\n",
       "4291   0.058289       1.037946       1.079461        1.372507     0.003855   \n",
       "4292   0.058109       1.041817       1.082342        1.376145     0.005139   \n",
       "4293   0.058188       1.035269       1.075146        1.366634    -0.004367   \n",
       "4294   0.059283       1.033384       1.072863        1.363495     0.000207   \n",
       "4295   0.064478       1.010751       1.048609        1.332089    -0.020650   \n",
       "4296   0.062998       1.019752       1.057790        1.343208     0.010879   \n",
       "4297   0.062503       1.017544       1.055042        1.339300    -0.000411   \n",
       "4298   0.063721       1.028146       1.065835        1.352695     0.012552   \n",
       "4299   0.063711       1.020242       1.057476        1.341551    -0.005733   \n",
       "4300   0.069765       0.998614       1.034268        1.311286    -0.020156   \n",
       "4301   0.065521       0.980886       1.014929        1.285487    -0.017294   \n",
       "4302   0.063888       0.984947       1.017958        1.288089     0.004528   \n",
       "4303   0.066543       0.993396       1.025617        1.296795     0.009252   \n",
       "4304   0.065495       0.998684       1.030104        1.301588     0.006301   \n",
       "4305   0.065457       1.003364       1.033795        1.305603     0.005686   \n",
       "4306   0.066839       0.994679       1.023719        1.291991    -0.007936   \n",
       "4307   0.069701       0.957916       0.984366        1.240614    -0.037576   \n",
       "4308   0.070245       0.946836       0.971789        1.222765    -0.012211   \n",
       "4309   0.068660       0.938727       0.962350        1.208747    -0.009333   \n",
       "4310   0.067700       0.961348       0.984573        1.234990     0.023990   \n",
       "\n",
       "      Close5DayChange  Close10DayChange  Close60DayChange  \n",
       "4291         0.000329          0.004525          0.002347  \n",
       "4292         0.000085          0.003116          0.002483  \n",
       "4293        -0.000778          0.001759          0.002323  \n",
       "4294        -0.001259          0.001392          0.002369  \n",
       "4295        -0.003163         -0.000095          0.002069  \n",
       "4296        -0.001758         -0.000715          0.002161  \n",
       "4297        -0.002868         -0.001392          0.002260  \n",
       "4298         0.000515         -0.000131          0.002352  \n",
       "4299        -0.000673         -0.000966          0.002184  \n",
       "4300        -0.000574         -0.001869          0.001919  \n",
       "4301        -0.006209         -0.003983          0.001523  \n",
       "4302        -0.005221         -0.004045          0.001636  \n",
       "4303        -0.005881         -0.002683          0.001813  \n",
       "4304        -0.003474         -0.002073          0.002023  \n",
       "4305         0.001695          0.000560          0.002211  \n",
       "4306         0.003566         -0.001321          0.001939  \n",
       "4307        -0.004855         -0.005038          0.001002  \n",
       "4308        -0.009147         -0.007514          0.000663  \n",
       "4309        -0.012274         -0.007874          0.000468  \n",
       "4310        -0.008613         -0.003459          0.000983  \n",
       "\n",
       "[20 rows x 22 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='Date', ascending=True)\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a73dc8",
   "metadata": {},
   "source": [
    "# Model Selection and train, test, val baseline scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ecd34444",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('targetencoder', TargetEncoder()),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None, gamma=None, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_delta_step=None, max_depth=None,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=100,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=None, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=None, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    }
   ],
   "source": [
    "mod = xgb.XGBClassifier()           #xgb.XGBRegressor(verbosity=1)\n",
    "te = ce.TargetEncoder()\n",
    "pipe = make_pipeline(te, mod)\n",
    "\n",
    "print(pipe)        #debugging need to remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f7a5ef",
   "metadata": {},
   "source": [
    "## split data in train n test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f00af8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "fc96993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3017 entries, 184 to 4271\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Open              3017 non-null   float64\n",
      " 1   High              3017 non-null   float64\n",
      " 2   Low               3017 non-null   float64\n",
      " 3   Close             3017 non-null   float64\n",
      " 4   Adj Close         3017 non-null   float64\n",
      " 5   Volume            3017 non-null   int64  \n",
      " 6   year              3017 non-null   int64  \n",
      " 7   month             3017 non-null   int64  \n",
      " 8   day               3017 non-null   int64  \n",
      " 9   30DayFwd          3001 non-null   float64\n",
      " 10  VolPctChange      3016 non-null   float64\n",
      " 11  5DayVol           3013 non-null   float64\n",
      " 12  30DayVol          2992 non-null   float64\n",
      " 13  252DayVol         2836 non-null   float64\n",
      " 14  Close30DRatio     2993 non-null   float64\n",
      " 15  Close60DRatio     2969 non-null   float64\n",
      " 16  Close252DRatio    2837 non-null   float64\n",
      " 17  CloseChange       3016 non-null   float64\n",
      " 18  Close5DayChange   3013 non-null   float64\n",
      " 19  Close10DayChange  3009 non-null   float64\n",
      " 20  Close60DayChange  2968 non-null   float64\n",
      "dtypes: float64(17), int64(4)\n",
      "memory usage: 518.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print( X_train.info() )    #debugging ststement remove\n",
    "#print( y_test.isna() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "101e7d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184     0.299624\n",
       "2661   -0.000458\n",
       "824    -0.039847\n",
       "386     0.068296\n",
       "3113    0.046564\n",
       "          ...   \n",
       "919     0.271686\n",
       "2550   -0.070737\n",
       "537     0.204196\n",
       "1220    0.100345\n",
       "4271    0.014456\n",
       "Name: 30DayFwd, Length: 3017, dtype: float64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train      #debugging statement remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "72882482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ANACONDA\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "F:\\ANACONDA\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('targetencoder', TargetEncoder(cols=[])),\n",
       "                ('xgbclassifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "#pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0ed81d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:37:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-209-c357aefd3127>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m '''\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mbaseline_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-182-e92c90d791b7>\u001b[0m in \u001b[0;36mget_model_scores\u001b[1;34m(mod, X_train, y_train, X_test, y_test, val_score, test_score)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mval_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[0mscore_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mscore_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \"\"\"\n\u001b[0;32m    499\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m     83\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'f'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[1;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'continuous'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "'''\n",
    "X_train = X_train.fillna(0)\n",
    "X_test.fillna(0)\n",
    "y_train.fillna(0)\n",
    "y_test.fillna(0)\n",
    "'''\n",
    "baseline_score = get_model_scores(pipe, X_train, y_train, X_test, y_test, test_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d4615120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_score': 0.9999995348639846,\n",
       " 'val_score': 0.999088975470272,\n",
       " 'test_score': 0.9991423142517383}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6a2510ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col</th>\n",
       "      <th>Imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30DayFwd</td>\n",
       "      <td>0.326230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High</td>\n",
       "      <td>0.317722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Close252DRatio</td>\n",
       "      <td>0.276123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Open</td>\n",
       "      <td>0.075513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Volume</td>\n",
       "      <td>0.004412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30DayVol</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Close10DayChange</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Close5DayChange</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CloseChange</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Close60DRatio</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Close30DRatio</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>252DayVol</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VolPctChange</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5DayVol</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>day</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>month</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>year</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adj Close</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Close</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Low</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Close60DayChange</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Col       Imp\n",
       "9           30DayFwd  0.326230\n",
       "1               High  0.317722\n",
       "16    Close252DRatio  0.276123\n",
       "0               Open  0.075513\n",
       "5             Volume  0.004412\n",
       "12          30DayVol  0.000000\n",
       "19  Close10DayChange  0.000000\n",
       "18   Close5DayChange  0.000000\n",
       "17       CloseChange  0.000000\n",
       "15     Close60DRatio  0.000000\n",
       "14     Close30DRatio  0.000000\n",
       "13         252DayVol  0.000000\n",
       "10      VolPctChange  0.000000\n",
       "11           5DayVol  0.000000\n",
       "8                day  0.000000\n",
       "7              month  0.000000\n",
       "6               year  0.000000\n",
       "4          Adj Close  0.000000\n",
       "3              Close  0.000000\n",
       "2                Low  0.000000\n",
       "20  Close60DayChange  0.000000"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = pd.DataFrame(\n",
    "    {\n",
    "        'Col': X_train.columns,\n",
    "       'Imp': pipe[-1].feature_importances_}\n",
    ")\n",
    "imp.sort_values(by='Imp', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca417118",
   "metadata": {},
   "source": [
    "# USE OLD FSIONED FOR loops for paameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2fc70806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ANACONDA\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "F:\\ANACONDA\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-200-81c31dc2b3fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting new model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mpipe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[0mcv_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-182-e92c90d791b7>\u001b[0m in \u001b[0;36mget_model_scores\u001b[1;34m(mod, X_train, y_train, X_test, y_test, val_score, test_score)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mval_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[0mscore_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mscore_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \"\"\"\n\u001b[0;32m    499\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "n_estimators = [100, 200, 300, 400, 500]\n",
    "learning_rate = [0.1, 0.2, 0.3, 0.4]\n",
    "tree_depth = [3, 4, 5, 6]\n",
    "subsample = [1, 0.8, 0.6, 0.3]\n",
    "cv_scores = []\n",
    "\n",
    "for estimator in n_estimators:\n",
    "    for rate in learning_rate:\n",
    "        for depth in tree_depth:\n",
    "            for sample in subsample:\n",
    "                print(\"Fitting new model\")\n",
    "                pipe[-1].set_params(n_estimators=estimator, learning_rate=rate, max_depth=depth, subsample=sample)\n",
    "                scores = get_model_scores(pipe, X_train, y_train, X_test, y_test)\n",
    "                cv_scores.append((scores['val_score'], scores['train_score'], estimator, rate, depth, sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "31bf001a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e877b00",
   "metadata": {},
   "source": [
    "## Setting best params to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "427ce9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.2, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=0.3,\n",
       "              tree_method='hist', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe[-1].set_params(n_estimators=200, learning_rate=0.2, max_depth=4, subsample=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "675da9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-201-f3c7b0cb086b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    805\u001b[0m                                                        **fit_and_score_kwargs)\n\u001b[0;32m    806\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcand_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m                                    (split_idx, (train, test)) in product(\n\u001b[0m\u001b[0;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                                    enumerate(cv.split(X, y, groups))))\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    330\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[0mtest_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[0mallowed_target_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype_of_target_y\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_target_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    646\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[0;32m    647\u001b[0m                     allowed_target_types, type_of_target_y))\n",
      "\u001b[1;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead."
     ]
    }
   ],
   "source": [
    "#ERROR CELL\n",
    "\n",
    "# list the parameters we want to load in the xgbclassifier__ notation is because we want to refer to\n",
    "# items inside of a pipeline\n",
    "param_grid = {\n",
    "    'xgbclassifier__n_estimators': [100, 200, 300, 400],\n",
    "    'xgbclassifier__max_depth': [3, 4, 5, 6],\n",
    "    'xgbclassifier__max_features': [0.3,0.6, 0.8, 1], \n",
    "    'xgbclassifier__subsample': [0.3,0.6, 0.8, 0.1]\n",
    "}\n",
    "\n",
    "# we'll apply this option for faster fitting -- a nice feature of xgboost\n",
    "pipe[-1].set_params(tree_method = 'hist')\n",
    "\n",
    "# import a splitter\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits = 3)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv = kfold, verbose = 1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7119fffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
